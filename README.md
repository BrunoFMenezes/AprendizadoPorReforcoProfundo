# Aprendizado Por Refor莽o Profundo
## Ebook DQN usando TorchRL
[Clique aqui para ir para o diret贸rio do Ebook ](https://github.com/BrunoFMenezes/prompts-recipe-to-create-a-ebook/tree/main)
## Classes de ReplayBuffer da TorchRL
https://github.com/pytorch/rl/blob/main/torchrl/data/replay_buffers/replay_buffers.py#L901
## Classes de Samplers da TorchRL
https://github.com/pytorch/rl/blob/main/torchrl/data/replay_buffers/samplers.py
### Tutorial Prioritazy
https://pytorch.org/rl/stable/reference/generated/torchrl.data.replay_buffers.PrioritizedSampler.html?highlight=prioritizedsampler#torchrl.data.replay_buffers.PrioritizedSampler
## Ideias de Novas Vers玫es
1. PER Buffer Duplo: come莽a usando um buffer e gera outro buffer com as melhores/piores trajet贸rias(experi锚ncias), ap贸s 50% do treinamento migra para o outro buffer e continua armanzenando nos dois buffer, um com as trajet贸rias normais e outro s贸 com as melhores/piores trajet贸rias.
2. [ COMPLETE A LISTA]
